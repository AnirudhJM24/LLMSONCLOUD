# HOW TO RUN LLMS SUPPORTED ON OLLAMA ON THE CLOUD AND USING IT THROUGH YOUR LOCAL MACHINE

## STEPS
- CREATE A NEW NOTEBOOK AND CHOOSE THE T4 RUNTIME
- CREATE THE server.py file on your local and upload it to your colab workspace
- COPY THE ollamaoncolab.ipynb NOTEBOOK INTO YOU COLAB NOTEBOOK AND RUN THE CELLS
- OPEN THE client.py ON YOUR MACHINE AND RUN IT 
